from transformers import AutoTokenizer
from collections import Counter
import re

filepath = r'C:/Users/ssimm/OneDrive/Desktop/S374865_HIT137_Assignment 2/HIT137-Assignment-2-Group-156/combined_text.txt'

tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

with open(filepath, 'r', encoding='utf-8') as file:
    text = file.read()
text = re.sub(r'[^a-zA-Z/s]', '', text)
tokens = tokenizer.tokenize(text)
count_words = Counter(tokens)
top30 = count_words.most_common(30)

print("the top 30 words in the file are as follows:")

for token, count in  top30:
    print(f"{token} occurs {count} times")